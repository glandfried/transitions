\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\input{auxiliar/tex/encabezado.tex}

\newif\ifen
\newif\ifes
\newcommand{\en}[1]{\ifen#1\fi}
\newcommand{\es}[1]{\ifes#1\fi}
\estrue

%opening
\title{Cooperación y ergodicidad}
\author{Gustavo Landfrierd}

\begin{document}

Los primeros debates sobre la teoría de la probabilidad estaban basados en el problema de la asignación "justa" de una apuestra (Pascal, Fermat).

Bayes habla de valor justo



De Finetti propone un concepto, que llama ``coherencia'', que se puede definir usando el concepto de Estrategia Evolutivamente Estable (ESS en inglés).

\begin{quotation} Finetti
En adoptant la définition [inter]subjective, ces règleslogiques découlent avec rigueur et facilité d’une seule condition très naturelle: celle de cohérence, qui nous oblige à prendre garde en évaluant les probabilités de ne pas donner la possibilité à un adversaire qui parie contre nous de gagner sûrement, par une \cancel{judicieuse} combinaison de ses mises sur les divers événements, quelle que soit l’éventualité qui se réalise.
Les théorèmes fondamentaux (probabilités totales, probabilités composées) ne sont que des corollaires immédiats de cette condition fondamentale.
\end{quotation}

La estrategia a adoptar bajo incertidumbre se define en términos evolutivos: es la estrategia de asignación de probabilidades que resiste la invasión de otras estrategias de asignación.
 

Mynard Smith sobre las aplicaciones de la teoría de juegos.
\begin{quotation}
    Game theory is more readily applied to biology than to the field of economic behaviour for which it was originally designed. (...).
    In seeking the solution of a game, the concept of human rationality is replaced by that of evolutionary stability.
    The advantage here is that there are good theoretical reasons to expect populations to evolve to stable states, whereas there are grounds for doubting whether human beings always behave rationally. \cite{maynardSmith1982-evolutionTheoryGames}
    
    A central assumption of classical game theory is that the players will behave rationally, and according to some criterion of self-interest.
    Such an assumption would clearly be out of place in an evolutionary context.
    Instead, the criterion of rationality is replaced by that of population dynamics and stability, and the criterion of self-interest by Darwinian fitness. (...).
    They lead to a new type of 'solution' to a game, the 'evolutionarily stable strategy' or ESS.
\end{quotation}


\\

\begin{quotation} \cite{gillespie1974-variance}
    The variance in the numbers of offspring of a genotype has two components, the within-generation component resulting from different individuals of the same genotype having different numbers of offspring, and a between-generation component due to the effects of a changing environment.
    This latter component has been recently investigated (GILLESPIE 1973); the former will be explored in this paper.
\end{quotation}


Parafraseando a Den Boer: the chance of survival of a population depends on a reciprocity system for spreading of the risk within populations and between populations of different species.
En sus palabras
\begin{quotation} \cite{denBoer1968-spreadingRisk}: 
    Which are the factors governing the distribution of a population over a number of localities?
    The daily contact with data from the field soon showed that change and variation predominate in the natural situation: populations do not fit
    nicely to some definite habitat definable in terms of important ecological factors.
    Heterogeneity and instability must not be considered as just a drawback of field data to be neglected.
    On the contrary, heterogeneity and/or instability must be recognized as fundamental features of a natural situation.
    The chance of survival of a population may even be increased, because the variation within the population makes it possible to cope with the variation in space and time of the habitat.
    This possibility led me to formulate the concept ``spreading of risk''~\cite{denBoer1968-spreadingRisk}: 1. Spreading of risk by phenotypic variation; 2. Spreading of risk in time (e.g. age classes); 3. Spreading of risk in space (e.g. different microenvironments); 4. Spreading of risk and relations to other species (monophagous vs polyphagous).
    The simultaneous occurrence of different kinds of heterogeneity can be expected to increase the spreading of risk.
    Biocoenosis rich in species may be expected to be more stable (provided with more intricate spreading of the risk) than one with few species.
    Hence, the ``balance of nature'' is not a balance but rather a relatively high degree of stability.

    It is supposed that the stabilization of animal numbers in natural populations is established by spreading of the risk, incidentally supplem ented by some kind of density limitation.
    The ``balance of nature'' must be the result of a complex and highly intricate system of spreading of the risk within populations and between populations of the same and especially of different species.
\end{quotation}

Ya Den Boer plantea como hipótesis un trade-off del ``spreading of the risk'', respecto de la densidad poblacional.
Seger se pregunta
\begin{quotation} \cite{denBoer1968-spreadingRisk}:
    Is there am evolutionary trade-off between \emph{expected} fitness and the \emph{variance} of fitness?
    Here, we show why there is only under certain circumstances~\cite{seger1987-betHedging}.

    Dampster~\cite{dempster1955-geometricMean} showed that for temporal fluctations on a scale of generations, the relevant measure of fitness is its geometric mean.
    Dampster result is the starting-point for all subsequent models of genetic evolution in temporally varying environments.

    The geometric mean is the natural measure of long-term fitness under temporal variation beacause, like population growth itself, it is inherently multiplicative rather than additive.
    It is therefore very sensitive to occasional small values.
    If there is any variation, the geometric mean will be less than the arithmetic mean.1

    Although the genotype with the highest geometric-mean fitness is favoured (and certainly goes to fixation), the \emph{populations's} geometric-mean fitness is not necessarily maximized at equilibrium [same example as \cite{starrfelt2012-bet}].
\end{quotation}
Y muestra el mismo ejemplo que Kokko.

\\

Starrfelt y Kokko
\begin{quotation} \cite{starrfelt2012-bet}
    Our aim is to review the conceptual foundation of bet-hedging as a mechanism that influences short-and long-term evolutionary processes.
    
    Assume that the environment can be either wet or dry.
    We consider four different genotypes: a drought-resistant genotype which forms the dry-year specialist ($A_{dry}$), a wet-year specialist ($A_{wet}$), a generalist ($A_{gen}$), also called a conservative bet-hedger), and finally a diversified genotype which gives rise to both wet year and dry year specialists ($A_div$, called a diversified bet-hedger).
    
    The highest geometric mean fitness will eventually prevail.
    Even though genotype $A_{gen}$ has a lower arithmetic mean fitness, it will invade and replace both a population of $A_{dry}$ and a population of $A_{wet}$.
    
    The generalist $A_{gen}$ is often called a ‘conservative’ bet-hedger because its success is a result of giving up high success in any year and instead avoiding very poor success in any year.
    In other words, it fulfils the definition of bet-hedging since a reduction in mean arithmetic fitness is accompanied by a reduction in the genotypic variance in fitness
    
    The last genotype ($A_{div}$) will invade and replace any population consisting of the other three genotypes. 
    Depending on the circumstances, one or the other type will be highly productive, and there is never a year where the genotype does universally badly.
    
    -- 
    
    The two advantages of bet-hedging: 1) reduced individual fitness variance and 2) reduced fitness correlation between individuals.
    
    
    The geometric mean of a series of n random variables (R 1,y ) can be written as
    
    \begin{equation}
    Geometric mean = E[log(R)]
    \end{equation}
    
    [Hacen una aproximación de la media geométrica en la que] It is now obvious that increasing the variance [(el producto de between-individual correlation ($\ro_i$) and the individual-level variance ($\sigma_i^2$)] in the absolute fitness values of a genotype will decrease the geometric mean.
    
    The geometric mean fitness of an allele can then be approximated by
    
    \begin{equation}
    G_i \approx \mu_i - \fraq{\text{Var}(R_i)}{2\mu_i} = \mu_i - \fraq{\ro_i \sigma_i^2}{2\mu_i}
    \end{equation}
    
    This is a recapitulation of the principle (Equation 10) that the success of a strategy depends on the mean arithmetic fitness, on the individual variance in reproductive success, and on the correlation between individuals.
    
    However, [this] Equation 17 itself is an approximation.
    When the population sizes are finite (and particularly small), then it is not correct to state that the geometric mean predicts the fixation of an allele.
    
    To return to our initial example of eggs in flooding nests: in large, well-mixed populations it does not matter whether a mother lays her eggs in one or two nests.
    Mathematically, the effect of variation in nest success becomes insignificant in this case because the number of individuals is very large.
    
    --
    
    Conservative versus diversified bet-hedging.
    
    In the case of the generalist strategy $A_{gen}$, the genotypic variance, $var(R_{gen})$, is reduced, as individuals always do reasonably well regardless of circumstances (small individual variance).
    This is a clear case of of the ‘bird in the hand’ metaphor, which makes the term ‘conservative bet-hedging strategy’ appropriate.
    
    The $A_{div}$ allele achieves the reduction in the genotypic variance in a different way.
    The majority of the reduction of genotypic variance of the A div allele is instead achieved by reducing the correlation (ρ div ) of reproductive success between individuals who share the same allele.
    
\end{quotation}


\\

Pigliucci 2001 \cite{pigliucci2001-plasticity} es un libro que trata exclusivamente sobre Phenotypic Plasticity

\\

Slatkin 1974 es un artículo muy corto, poco relevante. 
\begin{quotation} \cite{slatkin1974-evolutionaryBets}:
    Until the publication og Gillespie's article, selection resulting from differential variance in offspring number had been ignored.
\end{quotation}

\\

Jorge Peña
\begin{quotation}
    Change should be more precisely understood as Darwinian change, or differential replication.
    Differential replication means that different types replicate at different rates, so that fitter or more successful individuals reproduce faster or are imitated more often than less fit or less successful individuals.

    Public goods games (PGGs) are paradigmatic among such non-decomposable multiplayer games.
    PGGs are models of situations where individuals face the dilemma of providing and/or maintaining a public good: a common resource that is both non-excludable (no individual can be excluded from its consumption) and non-rivalrous (one individual’s use of the public good does not diminish its availability to another individual).
    Are typical examples of public goods whose abusive exploitation by non-contributing individuals may lead to the so-called tragedy of the commons, a situation in which nobody contributes and therefore no public good is produced or maintained.
    By far, the most well known PGG is the N-person prisoner’s dilemma (NPD). \cite{pena2012-phd}
\end{quotation}

\\

Hofbauer and Sigmund 2003:
\begin{quotation} \cite{hofbauer2003-evolutionaryGameDynamics}:
    This survey focuses on the mathematical core of evolutionary game theory and concentrates on deterministic evolutionary game dynamics, a dynamics which describes how the frequencies of strategies within a population change in time, according to the strategies' success.
    (...)
    The payoffs depend on the actions of the coplayers and hence on the frequencies of the strategies within the population. Since these frequencies change according to the payoffs, this yields a feedback loop.
    (...)
    There are many ``game dynamics'', which can be discrete or continuous, stochastic or deterministic.
    (...)
    The replicator equation, which was introduced in [Taylor: Evolutionarily stable strategies and game dynamics] and baptised in [Schuster, Sigmund: Replicator dynamics],
\end{quotation}


\\

Taylor 1978 presenta el primer replicator dynamic.
Es el primero que produce una versión dinámica que aplica al tipo de estudios que surgioeron a partir de la metodología de Mynard Smith, relacionando la noción de equilibrio estable de esas dinámicas con la noción de ESS. 
\begin{quotation} \cite{taylor1978-replicatorDynamic}
    
    Our main theorem is that under a non-degeneracy condition, an ESS is always stable for the continuous dynamic.
    This is not however true for the discrete dynamic, essentially because of an overshoot phenomenon.
    Finally we give an example of a dynamically stable equilibrium point which is not an ESS. 
    
    --
    
    We attempt to model the dynamics of the game both in the continuous case, with a system of non-linear first-order differential equations, and in the discrete case, with a system of non-linear difference equations.
    Using this model, we look at the notions of stability and asymptotic behavior.
    Our notion of stable equilibrium for the continuous dynamic includes, but is somewhat more general than, the notion of ESS.
    
    --
    
    Suppose we have a population of individuals who are playing a game in competition with one another.
    There are $n$ possible pure strategies available, numbered $1$ to $n$, and at each instant, every individual is using one of these strategies.
    For each strategy $i$ let $s_i$ be the proportion of individuals who are, at that moment, using strategy $i$.
    The probability vector $s=(s_1,s_2,\dots,s_n)$ is called the \emph{state vector} of the population.
    We assume that the payoff per unit time to an individual using strategy $i$ is a function $F(i|s)$ of the state $s$ of the population.
    We refer to $F(i|s)$ as the fitness of $i$ in state $s$.

    The basic idea is this: the more fit a strategy is at any moment, the more likely it is to be employed in the future. 
    The mechanism behind this is either that individuals tend to switch to strategies that are doing well, or that individuals bear offspring who tend to use the same strategies as their parents, and the fitter the individual, the more numerous his offspring.
    In any case, as time goes on, the strategy mix $s$ may change.
    A dynamic game theory will look at how the state vector $s$ moves with time, and will look for equilibrium states and examine their stability. 
    
    Let us define $F(q|s) = \sum s_i F(i|s)$.
    
    In order to discuss stability, we must now define a dynamic for the game. 
    There are undoubtedly many ways to do this, each related to certain hypotheses about the population.
    We will assume a population of haploid individuals, each using the same pure strategy throughout its lifetime, and producing offspring using the parent’s strategy. 
    Then the change in the population's strategy is determined by the rate at which the users of each strategy reproduce.
    The simplest hypothesis is that of exponential growth or decay. 
    So let us denote by $n_i$ the number of $i$-strategists in the population and by $N=\sum n_i$ the total number of individuals.
    Then the state of the population is $s=(s_i,\dots,s_n)$ where $s_i = n_i/N$ is the proportion of $i$-strategists, and $ \overset{.}{n} = r_i n_i$, where $r$, is the current growth rate of $n_i$. 
    It follows that $ \overset{.}{N} = \overline{r}_i N$, where $\overline{r} = \sum s_i r_i$ is the average growth rate.
    If we differentiatem $s_i = n_i/ N$, we get $s_i = s_i (r_i - \overline{r})$
    
    To put this into our game framework, let us suppose that the fitness $F(i|s)$ of a strategy is an estimate of the growth rate $r_i$.
    In terms of our reproductive model, this means we must choose our fitnesses so that in time $\Delta t$ each individual gives rise to $F(i|s) \Delta t$ additional individuals.
    Then our dynamic equation becomes
    
    \begin{equation}
     \overset{.}{s_i} = s_i (F(i|s) - \overbrace{\sum s_i F(i|s)}^{F(s|s)} )
    \end{equation}
    
    Letting $\hat{n}_i $ denote the new value of $n_i$, we have the difference equation $\hat{n}_i = n_i (r_i + 1)$.
    
    [Sin terminar, p 149]
    
    
\end{quotation}

\\

Sigmund junto a Schuster, publican en 1983
\begin{quotation} \cite{schuster1983-replicatorDynamics}
    Thus we see that essentially one type of equation models the evolution (1) of allele frequencies in a gene pool (2) of population densities in a habitat (3) of concentrations of polynucleotides in a flow reactor and (4) of probabilities of strategies for conflicts within one species.
    Let us emphasize that this result has not been obtained through a mathematicians desire to apply a pretty equation to as many fields as possible: the modelling leading to equations (1)-(4) proceeded independently in genetics, ecology, prebiotic chemistry and sociobiology.
    It is natural now to subsume the entities in the four models under a common heading: and Dawkins term of ``replicator'' seems just right.
    
    Let us subsume all these models under a common dynamics. We shall use the term ``replicator equation'' for differential equations of the type.
    
    \begin{equation}
    \ovserset{.}{x_i} = x_i (F_i(x_1, \dots, x_n) - \fraq{\phi}{c})
    \end{equation}
    
    where $c=\sum x_i$, the term $\phi = \sum x_i F_i$ ensures that $c$ is invariant (``state variables'' $(x_1, \dots, x_n)$ ).
    If the ``interaction term'' $F_i$ are homogeneous there is no loss in generality in assuming $c = 1$.
    If the $F_i$ are polynomials of degree $k$, we say that equation is a replicator equation of order k.
    The order is a measure for the complexity of the interactions between replicators.
    At order zero, the problem reduces to a simple optimization while higher orders yield frequency dependent selection taking kinetic, strategic or genetic features into account.
    
    Equation (5), then, is flexible enough to cover a great deal of evolution models, suggesting a unifying view of replicator selection from the primordial soup up to animal societies.
    Additional features to selective reproduction, like mutation or recombination, require modifications of this general framework, of course.
    
\end{quotation}

\\


\begin{quotation} \cite{harper2009-replicatorAsInference}:
    Let $x_i$ be the proportion of the population of the $i$-th type and denote the population distribution $x = (x_1 , \dots , x_n)$.
    The discrete replicator dynamic is:
    
    \begin{equation}
    x_i\prime = \fraq{x_i f_i(x)}{\overline{f}(x)}
    \end{equation}
    
    [With $\sum x_i = 1$, $f_i(x)$ the fitness of type $i$, $f=(f_i, \dots, f_n)$ the fitness landscape, $\overline{f}(x)=\sum x_i f_i(x)$ the average fitness, and $x_i\prime$ the frequency of type $i$ in the next generation.]
    
    A population of a particular distribution obtains information about the environment from the fitness landscape.

    Bayesian inference is a special case, formally, of the discrete replicator dynamic, since the fitness landscape in each coordinate may depend on the entire population distribution rather than only on the proportion of the i-type.
    
    A continuous version of the replicator equation is widely used and as a differential equation has more tractable tools for analysis.
    
    \begin{equation}
     \ovserset{.}{x_i} = \lim_{h \rightarrow 0} \fraq{x_i(t+h) - x_i{t}}{h} \approx x_i\prime - x_i = x_i \fraq{f_i(x)}{\overline{f}(x) - x_i} = x_i \fraq{f_i(x) - \overline{f}(x)}{\overline{f}(x)}
    \end{equation}
    
    is equivalent to the following equation after a change in velocity because $\overline{f}(x)$ can be assumed to be strictly positive:
    
    \begin{equation}
    \ovserset{.}{x_i} = x_i (f_i(x) - \overline{f}(x))
    \end{equation}
    
    This description, in light of the relationship to inference, identifies the replicator dynamic as a continuous inference process.
    
    A distribution $\hat{x}$ on the simplex is called an evolutionarily stable state of the replicator dynamic if $\hat{x} \cdot f(x) > x \cdot f(x)$ (in some neighborhood of $\hat{x}$).
    
    The concept of exponential families gives formal solutions
    to the continuous replicator dynamic.
    Natural selection acts to fit the available niches in a fitness landscape, arriving at the maximal entropy distribution allowed by the constraints of the landscape. In the absence of variation within the fitness landscape, the replicator dynamic is stable.
    
    The connections between inference and evolutionary game theory are not just formal coincidence.
    Information geometry explains the commonality.
    In information geometry, the replicator equation is known as the \emph{natural gradient}.
    The gradient flow of the Fisher information metric is the replicator equation.
    The replicator equation can now be understood as modeling the informational dynamics of the population distribution, moving in the direction of maximal local increase of potential with respect to the Fisher information, and ultimately converging to a minimal potential information state if a stablizing state (ESS) exists in the interior of the state space.
    
\end{quotation}

\\


Nowak and Page:
\begin{quotation}
\cite{page2002-unifyingEvolutionaryDynamics}
    There are numerous mathematical descriptions of the resulting evolutionary dynamics.
    In this paper, we show that apparently very different formulations are part of a single unified framework.
    We will now show that the replicator-dynamical is equivalent to the Price equation, while the replicator-mutator dynamic is equivalent to an expanded Price equation.
    
    \\
    
    We do not consider stochastic, spatial or individual-based approaches, which are mathematically more diverse and hence less amenable to any attempt of unification.
    Obviously, stochastic approaches that include finite population size effects are always more realistic.
    
    \\
    
    The quasispecies equation (1) lacks frequency-dependent selection, while the replicator equation (2) lacks mutation.
    Combining these two equations we obtain the ``replicator–mutator equation''
    
    \begin{equation}
        \ovserset{.}{x}_i = \sum^n_{j=1} x_j f_j(x) q_ji - x_i \overline{f}  
    \end{equation}
    
    Replication is error-prone; the probability that replication of sequence $i$ gives rise to sequence $j$ is given by $q_ij$.
    These quantities describe the mutation matrix $Q$.
    [With no mutation, this equation reduces to the replicator dynamic.]
    
    For continuous time, the Price equation is of the form (Price, 1972)
    
    \begin{equation}
    \overset{.}{E}(p) = \text{Cov}(f,p) + E(\overset{.}{p})
    \end{equation}
    
    The numerical value of an arbitrary trait of individual $i$ is given by $p_i$. The population average of this trait is given by $\overline{p} = E(p) = \sum p_i x_i$.
    The covariance of trait $p$ and fitness $f$ is given by $\text{Cov}(f,p)=\sum x_i f_i p_i - \overline{f}\overline{p}$.
    
\end{quotation}

\\

\begin{quotation} \cite{czegel2019-bayesianEvolution}

    Here we show, building on former results connecting replicator dynamics and Bayesian update, that (i) evolution of a hierarchical population under multilevel selection is equivalent to Bayesian inference in hierarchical Bayesian models and (ii) evolutionary transitions in individuality, driven by synergistic fitness interactions, is equivalent to learning the structure of hierarchical models via Bayesian model comparison.

    These correspondences support a learning theory-oriented narrative of evolutionary complexification: the complexity and depth of the hierarchical structure of individuality mirror the amount and complexity of data that have been integrated about the environment through the course of evolutionary history.
    
    A crucial preliminary condition is the alignment of interests: to undergo an evolutionary transition in individuality, organisms must exhibit cooperation, originating from genetic relatedness and/or synergistic fitness interactions
    However, the story does not end here: something must also maintain the alignment of interests subsequent to the transition.
    At any phase, the fate of the organism depends on selective forces at multiple levels that might be in conflict with each other.
    Incorporating the effects of multilevel selection is, therefore, a crucial element of understanding evolutionary transitions in individuality
    
    When the replication of particles (i.e. lower-level replicators) is not fully synchronized with the replication of the collective they belong to, or, in other words, when selective forces at different levels conflict, multilevel selection theory provides an effective description of the system
    
    A key ingredient of models of multilevel selection is the partitioning of fitness of particles to within-collective and between-collective components, once the collectives are defined.

    
\end{quotation}

\\

\begin{quotation} \cite{peters-cooperation2019.03.04}
    Our model assumes nothing more than that evolutionary processes are multiplicative and noisy.
    In this context, the evolutionary advantage of cooperation arises from the nonlinear dependence of growth rates on temporal fluctuations.
    By reducing the amplitude of fluctuations, pooling and sharing increase the time-average growth rate of the resources of cooperating entities.
    This paints a picture of cooperation driven by self-interest, not altruism, with cooperators outgrowing similar non-cooperators.
    
    Nor do we consider the cheating problem or the walk-away option (Aktipis 2016).
    Our cooperators are unable to break the cooperative pact.
    
    The insight that time averages may not be identical to expectation values was only reached in the development of statistical mechanics in the 19 th century.
    The development of ergodic theory in the 20th and 21st centuries provided the concepts that reveal the physically relevant aspect of stochastic processes like (Eq. 1).
\end{quotation}

\\

Okasha 2005:
\begin{quotation} \cite{okasha2005-multilevelTransitions}   
    A number of recent biologists have used multilevel selection theory to help explain the major transitions in evolution.
    I argue that in doing so, they have shifted from a synchronic to a diachronic formulation of the levels of selection question.
    
    Increasingly, biologists interested in explaining what Maynard-Smith and Szathmáry call the ‘major transitions in evolution’ have made use of ideas from multilevel selection theory (Buss 1987; Michod 1997, 1999; Maynard Smith and Szathmáry 1995; Michod and Roze 1999; Roze and Michod 2001; Frank 1998).
    
    The challenge is to understand these transitions in Darwinian terms.
    Why was it advantageous for the lower-level units to sacrifice their individuality, cooperate with one another, and form themselves into a larger corporate body?
    And how could such an arrangement, once first evolved, be evolutionarily stable?
    
    One possibility is that selection acted on the higher-level units themselves, leading them to evolve adaptations that minimize conflict and increase cooperation among their constituent parts.
    the general idea that the major transitions involve an interaction between selection at different levels is very widely accepted
    
    Traditionally the question has been formulated roughly as follows: the biological world is hierarchically organized—genes are nested within chromosomes, chromosomes within cells, cells within organisms, organisms within groups etc. Furthermore, natural selection will operate on any entities that exhibit ‘heritable variation in fitness’.
    
    the diachronic formulation of the levels of selection question (‘how did the levels in the biological hierarchy evolve initially?’) differs substantially from the synchronic formulation (‘at which hierarchical levels does selection now act?’).

    Damuth and Heisler (1988) offer a particularly clear discussion of the two meanings of multilevel selection, so I follow their treatment here.
    
    In MLS1, a collective’s fitness is defined as the average fitness [tamaño de la población] of the particles within the collective.
    In MLS2 a collective’s fitness is defined as the expected number of offspring collectives contributed to the next generation [growth rate].
    
    Most of the literature on ‘group selection’ has been concerned with MLS1: the aim has been to understand the evolution of an individual phenotype, often altruism, in a population subdivided into groups.
    By contrast, the macroevolutionary literature on species selection has been concerned with MLS2: the aim has been to understand the changing frequency of different types of species, not individuals, over geological time.
    
    In many circumstances the existence of one type of multilevel selection will imply the other.
    The collective that contributes the most particles to the next generation, and so is fittest by the MLS1 criterion, will often contribute the most collectives to the next generation, and hence be fittest by the MLS2 criterion too.
    (This will always be so if the number of particles per collective is constant.).
    So ordering the collectives by their MLS1 fitness and by their MLS2 fitness will often give the same result
    
    MLS1 is relevant to the early transitional stages, where cooperation spreads among the particles.
    This is essential if the collectives are to achieve the degree of cohesion necessary for collective fitness in the MLS2 sense to be a meaningful notion.
    
    Multilevel selection is conceptually characterized into two types, dubbed multilevel selection 1 (MLS1) and multilevel selection 2 (MLS2), both assuming that collectives form in a population of replicators, which themselves affect selection of lower-level units.
    In the case of MLS1, only temporary collectives form that periodically disappear to revert to an unstructured population of lower-level units (transient compartmentation).
    MLS2, on the other hand, involves collectives that last and reproduce indefinitely, hence being bona fide evolutionary units [29], see also [30]).
    
\end{quotation}

\\

\begin{quotation} \cite{damuth1988-multilevelSelection}
    [There are] two distinct bodies of thought in evolutionary biology, the group selection and the species selection traditions.

MLS1 y MLS2
\end{quotation}

 \\
 
\begin{quotation} \cite{capillaLasheras2021-betHedging}
    Explanations for the evolution of altruism via kin selection typically  focus on scenarios in which altruistic acts yield indirect fitness benefits to the actor by increasing the mean reproductive success of relatives (Hamilton).
    However, recent [sic] theory has highlighted that kin selection can also favor altruistic acts if they decrease variance in the reproductive success of relatives in unpredictable environments, a scenario termed “altruistic bet-hedging” (\cite{kennedy2018-betHedging})
\end{quotation}

\begin{quotation} \cite{kennedy2018-betHedging}:
    We derive Hamilton’s rule with explicit stochasticity, which predicts when organisms should pay a cost to influence the variance in the reproductive success of their relatives.
    We follow the established method of capturing fitness effects as regression slopes.
\end{quotation}

\\

\begin{quotation}  \cite{yaari2010-cooperationEvolution}
While in an additive context the emergence and survival of cooperation requires special conditions (especially some level of reward, punishment, reciprocity), we find that in the multiplicative random context the emergence of cooperation is much more natural and effective.
\end{quotation}


{\footnotesize
\bibliographystyle{auxiliar/biblio/plos2015.bst}
\bibliography{auxiliar/biblio/biblio_notUrl.bib}
}

\end{document}
